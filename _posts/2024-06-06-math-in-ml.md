---
layout: post
title: 如何学习机器学习中的数学？
date: 2024-06-06 19:03:00
description:
tags: 
categories:
---

谢邀。assume题主掌握基本的微积分和线性代数知识。

概率论可以参考[Stanford CS 109](https://web.stanford.edu/class/cs109/)，不仅覆盖了基础的probability和random variable，还介绍了一些基础的统计学习知识，包括regression/classification/naive bayes/bootstrap/mle/deep learning等。lecture videos可以参考Chris Piech的影片：https://www.youtube.com/playlist?list=PLoROMvodv4rOpr_A7B9SriE_iZmkanvUg。

如果只学过比较理论的线性代数基础知识，可以看一下由Stephen Boyd设计的[Stanford EE 263](https://ee263.stanford.edu/)，这门课介绍线性代数在engineering中的应用。可惜lecture videos只有上古时期的了：https://www.youtube.com/playlist?list=PL06960BA52D0DB32B。

如果想深入理解机器学习的算法，凸优化知识是必不可少的！可以看Stephen Boyd教授大名鼎鼎的[Stanford EE 364A](https://web.stanford.edu/class/ee364a/index.html)，这门课介绍了duality/estimation/(un)constrained optimization/interior point method/KKT等知识，学完能对凸优化有一定的了解，更有利于理解ML。庆幸的是，前几个月Stanford Online上传了最新版的Lecture Videos：https://www.youtube.com/playlist?list=PLoROMvodv4rMJqxxviPa4AmDClvcbHi6h。

还有需要了解基础的Matrix Calculus知识，读[Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)！这本书给的都是结论，没有任何理论推导。可以在读这本书之前先看[The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/)。

传统的机器学习算法可以参考[Elements of Statistical Learning](https://hastie.su.domains/Papers/ESLII.pdf)，这本书很硬核，是Introduction to Statistical Learning的加强版。

如果对强化学习感兴趣，可以看[Berkeley EE 290](https://people.eecs.berkeley.edu/~jiantao/2902021spring/material.html)的lecture notes，这门课介绍了Multi-Armed Bandits和强化学习理论。此外，可以看西湖大学赵世钰老师的《[强化学习的数学原理](https://www.bilibili.com/video/BV1r3411Q7Rr)》，这门网课深入浅出，用数学把强化学习的整个理论框架理得非常完善。

Learning Theory可以看[Stanford CS229M/STATS214](https://web.stanford.edu/class/stats214/)，介绍各类bound/kernel/regularization背后的原理和Non-Convex Optimization，Lecture Videos可以参考https://www.youtube.com/playlist?list=PLoROMvodv4rP8nAmISxFINlGKSK4rbLKh。